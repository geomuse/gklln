# ğŸŒŸ ä»€ä¹ˆæ˜¯ä¼˜åŒ–ï¼Ÿ

**ä¼˜åŒ–ï¼ˆOptimizationï¼‰** æ˜¯æŒ‡åœ¨ä¸€ç»„å¯è¡Œè§£ä¸­ï¼Œå¯»æ‰¾ä½¿ç›®æ ‡å‡½æ•°ï¼ˆcost function æˆ– objective functionï¼‰æœ€å¤§åŒ–æˆ–æœ€å°åŒ–çš„è§£çš„è¿‡ç¨‹ã€‚

* **ç›®æ ‡å‡½æ•°**ï¼šéœ€è¦è¢«ä¼˜åŒ–ï¼ˆæœ€å¤§åŒ–æˆ–æœ€å°åŒ–ï¼‰çš„å‡½æ•°ï¼Œæ¯”å¦‚åˆ©æ¶¦ã€é£é™©ã€è¯¯å·®ç­‰ã€‚
* **çº¦æŸæ¡ä»¶**ï¼šé™åˆ¶è§£çš„æ¡ä»¶ï¼Œæ¯”å¦‚é¢„ç®—é™åˆ¶ã€ç‰©ç†æ¡ä»¶ã€æ³•å¾‹æ¡ä»¶ç­‰ã€‚

---

# ğŸš© ä¼˜åŒ–æ–¹æ³•åˆ†ç±»

## 1ï¸âƒ£ æ— çº¦æŸä¼˜åŒ–

* æ²¡æœ‰ä»»ä½•é™åˆ¶æ¡ä»¶ï¼Œç›´æ¥å¯»æ‰¾æå€¼ç‚¹ã€‚
* å¸¸è§æ–¹æ³•ï¼š

  * æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰
  * ç‰›é¡¿æ³•ï¼ˆNewtonâ€™s Methodï¼‰
  * å…±è½­æ¢¯åº¦æ³•ï¼ˆConjugate Gradientï¼‰

## 2ï¸âƒ£ æœ‰çº¦æŸä¼˜åŒ–

* è§£å¿…é¡»æ»¡è¶³ä¸€ç³»åˆ—çº¦æŸæ¡ä»¶ã€‚
* å¸¸è§æ–¹æ³•ï¼š

  * æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼ˆLagrange multipliersï¼‰
  * å†…ç‚¹æ³•ï¼ˆInterior Point Methodsï¼‰
  * ç½šå‡½æ•°æ³•ï¼ˆPenalty Methodsï¼‰

---

## 3ï¸âƒ£ ç¡®å®šæ€§ä¼˜åŒ–

* å‡è®¾æ‰€æœ‰ä¿¡æ¯æ˜¯å‡†ç¡®å·²çŸ¥çš„ã€‚
* ä¾‹å¦‚ï¼šçº¿æ€§è§„åˆ’ï¼ˆLPï¼‰ã€éçº¿æ€§è§„åˆ’ï¼ˆNLPï¼‰ã€æ•´æ•°è§„åˆ’ï¼ˆIPï¼‰ã€‚

## 4ï¸âƒ£ éšæœºä¼˜åŒ–

* åœ¨ä¸ç¡®å®šæ€§æˆ–éšæœºæ€§æ¡ä»¶ä¸‹è¿›è¡Œä¼˜åŒ–ã€‚
* ä¾‹å¦‚ï¼šæ¨¡æ‹Ÿé€€ç«ï¼ˆSimulated Annealingï¼‰ã€é—ä¼ ç®—æ³•ï¼ˆGAï¼‰ã€ç²’å­ç¾¤ä¼˜åŒ–ï¼ˆPSOï¼‰ã€‚

---

## 5ï¸âƒ£ ç»„åˆä¼˜åŒ–ï¼ˆç¦»æ•£ä¼˜åŒ–ï¼‰

* ä¼˜åŒ–å¯¹è±¡æ˜¯ç¦»æ•£çš„ï¼ˆå¦‚æ•´æ•°ã€æ’åˆ—ç»„åˆï¼‰ã€‚
* ä¾‹å¦‚ï¼šæ—…è¡Œå•†é—®é¢˜ï¼ˆTSPï¼‰ã€èƒŒåŒ…é—®é¢˜ã€‚

---

# ğŸ’¡ å¸¸ç”¨ä¼˜åŒ–ç®—æ³•ä¸¾ä¾‹

| æ–¹æ³•    | é€‚ç”¨åœºæ™¯         | æ˜¯å¦æœ‰çº¦æŸ | æ˜¯å¦å…¨å±€ |
| ----- | ------------ | ----- | ---- |
| æ¢¯åº¦ä¸‹é™æ³• | å‡¸å‡½æ•°ã€æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ | æ—      | å±€éƒ¨   |
| ç‰›é¡¿æ³•   | äºŒé˜¶å¯å¯¼å‡½æ•°       | æ—      | å±€éƒ¨   |
| å†…ç‚¹æ³•   | çº¿æ€§æˆ–éçº¿æ€§çº¦æŸä¼˜åŒ–   | æœ‰     | å±€éƒ¨   |
| æ¨¡æ‹Ÿé€€ç«  | å¤§è§„æ¨¡å¤æ‚ç»„åˆä¼˜åŒ–    | æ— /æœ‰   | è¿‘ä¼¼å…¨å±€ |
| é—ä¼ ç®—æ³•  | ç»„åˆä¼˜åŒ–ã€å‚æ•°æœç´¢    | æ— /æœ‰   | è¿‘ä¼¼å…¨å±€ |
| ç²’å­ç¾¤ä¼˜åŒ– | é»‘ç®±å‡½æ•°ã€å¤æ‚ç³»ç»Ÿ    | æ— /æœ‰   | è¿‘ä¼¼å…¨å±€ |

---

# ğŸ¯ åº”ç”¨é¢†åŸŸ

âœ… æŠ•èµ„ç»„åˆä¼˜åŒ–
âœ… æœºå™¨å­¦ä¹ æ¨¡å‹å‚æ•°è°ƒä¼˜
âœ… ç¥ç»ç½‘ç»œè®­ç»ƒ
âœ… ç”Ÿäº§è®¡åˆ’ä¸è°ƒåº¦
âœ… ç‰©æµè·¯å¾„è§„åˆ’
âœ… èƒ½æºç®¡ç†
âœ… ç»“æ„è®¾è®¡ï¼ˆå·¥ç¨‹ï¼‰

---

# ğŸ§‘â€ğŸ’» Python ä¼˜åŒ–æ–¹æ³•èŒƒä¾‹

## ä¾‹å­ï¼šä½¿ç”¨ **SciPy** åº“åšç®€å•æ— çº¦æŸä¼˜åŒ–ï¼ˆæœ€å°åŒ–å‡½æ•°ï¼‰

```python
import numpy as np
from scipy.optimize import minimize

# å®šä¹‰ç›®æ ‡å‡½æ•°ï¼ˆæ¯”å¦‚ç®€å•çš„äºŒæ¬¡å‡½æ•°ï¼‰
def objective(x):
    return x[0]**2 + x[1]**2 + 1

# åˆå§‹çŒœæµ‹
x0 = [1, 2]

# è°ƒç”¨minimizeå‡½æ•°ï¼Œä½¿ç”¨BFGSæ–¹æ³•ï¼ˆæ‹Ÿç‰›é¡¿æ³•ï¼‰
result = minimize(objective, x0, method='BFGS')

print("æœ€ä¼˜è§£ï¼š", result.x)
print("æœ€å°å€¼ï¼š", result.fun)
```

âœ… è¾“å‡ºï¼š

```
æœ€ä¼˜è§£ï¼š [0. 0.]
æœ€å°å€¼ï¼š 1.0
```

> è¿™ä¸ªä¾‹å­è¡¨ç¤ºäºŒæ¬¡å‡½æ•° $f(x, y) = x^2 + y^2 + 1$ çš„æœ€å°å€¼åœ¨ (0, 0) ç‚¹å¤„ï¼Œå€¼ä¸º 1ã€‚

---

## å¸¦çº¦æŸä¼˜åŒ–ä¾‹å­

```python
from scipy.optimize import minimize

# ç›®æ ‡å‡½æ•°
def objective(x):
    return x[0]**2 + x[1]**2

# çº¦æŸï¼šx0 + x1 = 1
def constraint_eq(x):
    return x[0] + x[1] - 1

# è¾¹ç•Œ
bounds = [(0, None), (0, None)]

# çº¦æŸä»¥å­—å…¸å½¢å¼ç»™å‡º
constraints = {'type': 'eq', 'fun': constraint_eq}

# åˆå§‹çŒœæµ‹
x0 = [0.5, 0.5]

result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)

print("æœ€ä¼˜è§£ï¼š", result.x)
print("æœ€å°å€¼ï¼š", result.fun)
```

âœ… è¾“å‡ºï¼š

```
æœ€ä¼˜è§£ï¼š [0. 1.]
æœ€å°å€¼ï¼š 1.0
```

---

# ğŸ—ºï¸ æ€»ç»“

âœ… ä¼˜åŒ–æ–¹æ³•åˆ†ä¸ºå¾ˆå¤šç§ï¼Œå¯æ ¹æ®é—®é¢˜ç‰¹æ€§ï¼ˆè¿ç»­/ç¦»æ•£ã€æœ‰æ— çº¦æŸã€æ˜¯å¦éšæœºï¼‰æ¥é€‰å–
âœ… åœ¨æœºå™¨å­¦ä¹ ã€é‡‘èã€å·¥ç¨‹ã€ç‰©æµç­‰éƒ½æœ‰å¤§é‡åº”ç”¨
âœ… Python ä¸­å¸¸ç”¨ `scipy.optimize`, `cvxpy`, `pyomo`, `sklearn` ç­‰å·¥å…·åº“

---