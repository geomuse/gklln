---
layout: post
title:  python网络爬虫实战-项目实战china money
date:   2025-08-10 09:01:00 +0800
tags: 
    - python
    - web
image: 06.jpg
---

大家好，我是python网络爬虫这门课程的主要讲师geo

我们来建立一个专门爬取中国外汇交易中心（ChinaMoney）网站财务报告和评级报告的爬虫系统

```bash
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.chinamoney.org.cn', port=443): Max retries exceeded with url: /chinese/cqcwbglm/ (Caused by SSLError(SSLError(1, '[SSL: UNSAFE_LEGACY_RENEGOTIATION_DISABLED] unsafe legacy renegotiation disabled (_ssl.c:1028)')))
```

如果按照普通爬虫会遇到这个问题，但是要解决这问题，可以从很多有趣的角度思考

我们先从chatgpt得到这个代码进一步解释需要更新ssl协议.因为ssl协议旧版不能用了

在`terminal`执行`export OPENSSL_CONF=openssl.cnf`更新ssl协议

我们是通过`selenium`的工具进行爬取数据

做了三种“反反爬虫”版本（普通版、经典版、豪华版）

普通版就旧版格式,不支持代理ip和headers

典型版,不支持代理ip

豪华版,支持所有反爬虫技术

```py
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import WebDriverException

# 代理IP列表.
proxy_list = ['ip1:port1', 'ip2:port2', 'ip3:port3', ...]

# 配置Chrome选项.
Firefox_options = Options()
Firefox_options.add_argument('--proxy-server={}'.format(proxy_list[0]))

# 循环尝试不同的代理IP.
for proxy in proxy_list:
    try:
        # 创建WebDriver实例.
        browser = webdriver.Firefox(options=Firefox_options)
        
        # 进行爬取操作
        # ...
        
        # 如果成功执行爬取操作，跳出循环.
        break # 这很重要,不然会一直重复换ip执行同一个爬虫.
    
    except # 建议添加时间超出机制. 
        
    except WebDriverException as e:
        # 处理代理IP失败的情况.
        print('Proxy IP {} failed. Trying another IP.'.format(proxy))
        
        # 切换到下一个代理IP.
        Firefox_options = Options()
        Firefox_options.add_argument('--proxy-server={}'.format(proxy))

# 关闭browser.
browser.close()
```

整个框架如上，主要通过IP池进行反爬虫

我把代码放到我个人Github里

https://github.com/geomuse/download-china-money?tab=readme-ov-file