---
layout: post
title:  python网络爬虫实战-beautiful soup
date:   2025-07-28 09:01:00 +0800
tags: 
    - python
    - web
image: 02.jpg
---

大家好，我是python网络爬虫这门课程的主要讲师geo x telos lab

### beautiful soup

Python 的一个 HTML/XML 解析库，常用于网页爬虫中解析 HTML 内容。

```bash
pip install beautifulsoup4
pip install requests
```

如果不用 `html.parser`

```bash
pip install lxml
pip install html5lib
```

## 搭配 requests 读取网页

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")  # 也可用 "lxml" 或 "html5lib"
```

## 基本语法

### 查找单个标签（find）

```python
title_tag = soup.find("title")
print(title_tag.text)
```

### 查找多个标签（find\_all）

```python
links = soup.find_all("a")
for link in links:
    print(link.get("href"))
```

### 使用 CSS Selector（select）

```python
nav_links = soup.select("nav ul li a")
```

## 实例操作

### 获取标题：

```python
print(soup.title.string)
```

### 获取图片：

```python
imgs = soup.find_all("img")
for img in imgs:
    print(img["src"])
```

### 获取所有链接文字与链接：

```python
for a in soup.find_all("a"):
    print(a.text, a["href"])
```

### 获取表格数据：

```python
table = soup.find("table")
rows = table.find_all("tr")
for row in rows:
    cols = row.find_all("td")
    data = [col.text.strip() for col in cols]
    print(data)
```

## 提取属性与文本

```python
tag = soup.find("a")
print(tag["href"])         # 属性
print(tag.get("href"))     # 推荐
print(tag.text.strip())    # 文本
```

## 高级技巧

### 使用正则表达式：

因为返回一个 `list of Tag` -> `soup[0]`

```python
import re
soup = soup.find_all("a", href=re.compile("iana"))
print(soup[0].get('href'))
```

### 组合条件查找：

```python
soup.find_all("div", class_="news", id="top")
```

### 嵌套结构遍历：

```python
container = soup.find("div", class_="box")
for p in container.find_all("p"):
    print(p.text)
```

## 实战案例：爬取豆瓣书籍排行榜

```python
import requests
from bs4 import BeautifulSoup

url = "https://book.douban.com/top250"
headers = {"User-Agent": "Mozilla/5.0"}
res = requests.get(url, headers=headers)
soup = BeautifulSoup(res.text, "lxml")

books = soup.select(".pl2 a")
for book in books:
    print(book.text.strip(), book.get("href"))
```

```bash
红楼梦 https://book.douban.com/subject/1007305/
活着 https://book.douban.com/subject/4913064/
哈利·波特 https://book.douban.com/subject/24531956/
1984 https://book.douban.com/subject/4820710/
三体全集
```