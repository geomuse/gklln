---
layout: post
title:  python网络爬虫实战-requests 反爬虫技术
date:   2025-07-28 09:01:00 +0800
tags: 
    - python
    - web
image: 02.jpg
---

# 添加请求头（headers）

某些网站会发现这不是一个由正常游览器发送的请求，于是可能返回异常结果，导致网页爬取失败，于是请求头就解决这个问题。

```python
headers = {
    'User-Agent': 'Mozilla/5.0',
}
response = requests.get('https://example.com', headers=headers)
```

# 添加 URL 参数

如果要附加额外信息，利用params参数就能直接传递这种信息

```python
params = {'q': 'python', 'lang': 'en'}
response = requests.get('https://httpbin.org/get', params=params)
```

<!-- 
#### 发送 JSON 数据

```python
json_data = {'key': 'value'}
response = requests.post('https://httpbin.org/post', json=json_data)
``` -->

# 上传文件

```python
files = {'file': open('test.txt', 'rb')}
response = requests.post('https://httpbin.org/post', files=files)
```

# 处理超时和异常

```python
try:
    response = requests.get('https://example.com', timeout=5)
except requests.Timeout:
    print('请求超时')
except requests.RequestException as e:
    print(f'请求失败: {e}')
```

# 使用会话（Session）保持登录状态

```python
session = requests.Session()
session.get('https://httpbin.org/cookies/set/sessioncookie/123456789')
r = session.get('https://httpbin.org/cookies')
print(r.text)
```

# 代理设置

```python
proxies = {
    'http': 'http://127.0.0.1:8080',
    'https': 'https://127.0.0.1:8080',
}
response = requests.get('https://httpbin.org/get', proxies=proxies)
```

# 自带身份验证

```py
import requests 
from requests.auth import HTTPBasicAuth

r = requests.get('https://ssr3.scrape.center/',verify=False,auth=HTTPBasicAuth('admin','admin'))

print(r.status_code)
```