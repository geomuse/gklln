---
layout: post
title:  python贪吃蛇游戏项目-建构贪吃蛇gym代码
date:   2025-08-03 09:01:00 +0800
tags: 
    - python
    - game
image: 03.jpg
---

大家好，我是python游戏开发这门课程的主要框架师geo

利用pygame建立的游戏没有办法训练需要基于gym环境下才能训练

在gym中，每一个环境（Environment）都必须实现一组统一接口（standard API），这使得不同的强化学习算法能够在不同的环境中无缝运行

## gym 中的必要的统一接口

| 概念                 | 说明                        |
| ------------------ | ------------------------- |
| `env.reset()`      | 重置环境并返回初始状态               |
| `env.step(action)` | 执行动作，返回：新的状态、奖励、是否终止、额外信息 |
| `observation`      | 当前状态，可能是向量、图像等            |
| `action`           | 采取的动作，离散或连续               |
| `reward`           | 当前动作获得的奖励                 |
| `done`             | 是否达到终止条件                  |
| `env.render()`     | 显示当前环境状态（部分支持图形）          |
| `close` | 关闭环境，释放资源，尤其在渲染窗口开启时需要 |

```py
import gym 
from gym import spaces
import numpy as np
import pickle
from pygame_math_snake import snake

class SnakeEnv(gym.Env):

    def __init__(self):
        super(SnakeEnv, self).__init__()
        self.snake_game = snake()
        # 定义动作空间和状态空间
        self.action_space = spaces.Discrete(4)  # 假设游戏有4个动作可选：上、下、左、右
        self.observation_space = spaces.Box(low=0, high=255,
                                             shape=(self.snake_game.window_height, self.snake_game.window_width, 3),
                                               dtype=np.uint8)  # 假设游戏状态是RGB图像，大小为(window_height, window_width)

    def reset(self):
        return self.snake_game.reset()

    def step(self,action):
        return self.snake_game.step(action)

    def render(self,mode=None):
        # 在屏幕上显示游戏状态，这里需要调用原始snake类的渲染方法
        self.snake_game.render(mode=mode)

    def close(self):
        self.snake_game.close()

    def run(self):
        action = self.snake_game.render(mode='h')
        if action != None :
            print(action)
        return self.step(action)
    
    def random(self):
        action = self.action_space.sample()  # sample.
        if action != None :
            print(action)
        return self.step(action)
    
    def rl_run(self,observation):
        with open('data/q_table.pkl', 'rb') as f:
            q_table = pickle.load(f)
        
        action = np.argmax(q_table[observation, :])
        return env.step(action)

    def framework(self,mode=None):
        observation = self.reset()
        done = False

        if mode in ('sample','human' , 'h' ,'rl'):
            match mode :
                case 'sample':
                    while not done:
                        observation, reward, done, _ = self.random()
                case 'human' | 'h': 
                    while not done:
                        observation, reward, done, _ = self.run()
                case 'rl' :
                    while not done:
                        next_observation , _ , done , _ = self.rl_run(observation)
                        self.render()
                        observation = next_observation

if __name__ == '__main__':

    env = SnakeEnv()
    env.framework(mode='h')
```